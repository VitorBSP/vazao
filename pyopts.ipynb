{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pygrinder import mcar, masked_fill\n",
    "from pypots.imputation import SAITS, CSDI\n",
    "from pypots.data import load_specific_dataset\n",
    "from pypots.utils.metrics import cal_mae\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/vazoes_CA_20_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Vazao1_CA_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 335.,  329.,  278., ..., 2036., 1004.,  593.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mask = [1 if y_ is np.nan else 0 for y_ in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mask = np.array(missing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = masked_fill(Y, 1 - missing_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"X\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([nan, nan, nan, ..., nan, nan, nan])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_univariado = Y.values.reshape(1, len(Y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:59:52 [INFO]: No given device, using default device: cpu\n",
      "2023-11-03 19:59:52 [WARNING]: saving_path not given. Model files and tensorboard file will not be saved.\n",
      "/home/hartb/anaconda3/lib/python3.11/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "2023-11-03 19:59:52 [INFO]: Model initialized successfully with the number of trainable parameters: 658,688\n"
     ]
    }
   ],
   "source": [
    "saits = SAITS(n_steps=48, n_features=0, n_layers=1, d_model=256, d_inner=128, n_heads=4, d_k=64, d_v=64, dropout=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 335.],\n",
       "        [ 329.],\n",
       "        [ 278.],\n",
       "        ...,\n",
       "        [2036.],\n",
       "        [1004.],\n",
       "        [ 593.]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 20:00:36 [ERROR]: Exception: mat1 and mat2 shapes cannot be multiplied (8633x2 and 0x256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training got interrupted. Model was not trained. Please investigate the error printed above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/base.py:276\u001b[0m, in \u001b[0;36mBaseNNImputer._train_model\u001b[0;34m(self, training_loader, val_loader)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 276\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mforward(inputs)\n\u001b[1;32m    277\u001b[0m \u001b[39m# use sum() before backward() in case of multi-gpu training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/saits/modules/core.py:159\u001b[0m, in \u001b[0;36m_SAITS.forward\u001b[0;34m(self, inputs, diagonal_attention_mask, training)\u001b[0m\n\u001b[1;32m    157\u001b[0m     diagonal_attention_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m imputed_data, [X_tilde_1, X_tilde_2, X_tilde_3] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process(\n\u001b[1;32m    160\u001b[0m     inputs, diagonal_attention_mask\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m training:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# if not in training mode, return the classification result only\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/saits/modules/core.py:104\u001b[0m, in \u001b[0;36m_SAITS._process\u001b[0;34m(self, inputs, diagonal_attention_mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m input_X_for_first \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X, masks], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m input_X_for_first \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_1(input_X_for_first)\n\u001b[1;32m    105\u001b[0m enc_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_enc(input_X_for_first)\n\u001b[1;32m    107\u001b[0m )  \u001b[39m# namely, term e in the math equation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8633x2 and 0x256)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/hartb/Estudos/vazao/pyopts.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hartb/Estudos/vazao/pyopts.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m saits\u001b[39m.\u001b[39mfit({\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m: array_univariado})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/saits/model.py:277\u001b[0m, in \u001b[0;36mSAITS.fit\u001b[0;34m(self, train_set, val_set, file_type)\u001b[0m\n\u001b[1;32m    269\u001b[0m     val_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    270\u001b[0m         val_set,\n\u001b[1;32m    271\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    272\u001b[0m         shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[1;32m    276\u001b[0m \u001b[39m# Step 2: train the model and freeze it\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model(training_loader, val_loader)\n\u001b[1;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_state_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model_dict)\n\u001b[1;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()  \u001b[39m# set the model as eval status to freeze it.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/base.py:352\u001b[0m, in \u001b[0;36mBaseNNImputer._train_model\u001b[0;34m(self, training_loader, val_loader)\u001b[0m\n\u001b[1;32m    350\u001b[0m logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTraining got interrupted. Model was not trained. Please investigate the error printed above.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39mRuntimeWarning\u001b[39;00m(\n\u001b[1;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTraining got interrupted. Please investigate the error printed above.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel got trained and will load the best checkpoint so far for testing.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt want it, please try fit() again.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Training got interrupted. Model was not trained. Please investigate the error printed above."
     ]
    }
   ],
   "source": [
    "saits.fit({\"X\": array_univariado})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:08:23 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Database)...\n",
      "2023-11-03 19:08:23 [INFO]: Starting preprocessing physionet_2012...\n",
      "2023-11-03 19:08:23 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2023-11-03 19:08:23 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2023-11-03 19:08:23 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2023-11-03 19:08:24 [INFO]: Loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "data = load_specific_dataset('physionet_2012')  # PyPOTS will automatically download and extract it.\n",
    "X = data['X']\n",
    "num_samples = len(X['RecordID'].unique())\n",
    "X = X.drop(['RecordID', 'Time'], axis = 1)\n",
    "X = StandardScaler().fit_transform(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(num_samples, 48, -1)\n",
    "X_intact, X, missing_mask, indicating_mask = mcar(X, 0.1) # hold out 10% observed values as ground truth\n",
    "X = masked_fill(X, 1 - missing_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 0., 1., 0.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 0., 0.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.]],\n",
       " \n",
       "        [[1., 1., 1., ..., 1., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1., 1., 1., ..., 1., 0., 0.],\n",
       "         [1., 1., 1., ..., 0., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.]],\n",
       " \n",
       "        [[1., 1., 1., ..., 0., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.],\n",
       "         [1., 1., 1., ..., 1., 0., 1.]],\n",
       " \n",
       "        [[1., 1., 1., ..., 1., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32),)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - missing_mask,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11988"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Data', 'Vazao_CA', 'Vazao1_CA_1d', 'Vazao2_CA_1d',\n",
       "       'Vazao1_CA_7d', 'Vazao2_CA_7d', 'Vazao1_CA_15d', 'Vazao2_CA_15d',\n",
       "       'Vazao1_CA_30d', 'Vazao2_CA_30d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = data[['Vazao_CA', 'Vazao1_CA_1d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8633"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:29:50 [INFO]: No given device, using default device: cpu\n",
      "2023-11-03 19:29:50 [INFO]: Model files will be saved to tutorial_results/imputation/mrnn/20231103_T192950\n",
      "2023-11-03 19:29:50 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/mrnn/20231103_T192950/tensorboard\n",
      "2023-11-03 19:29:50 [INFO]: Model initialized successfully with the number of trainable parameters: 168,199\n"
     ]
    }
   ],
   "source": [
    "from pypots.optim import Adam\n",
    "from pypots.imputation import MRNN\n",
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# initialize the model\n",
    "# initialize the model\n",
    "mrnn = MRNN(\n",
    "    n_steps=len(V),\n",
    "    n_features=1,\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # Set it to None to use the default device (will use CPU if you don't have CUDA devices).\n",
    "    # You can also set it to 'cpu' or 'cuda' explicitly, or ['cuda:0', 'cuda:1'] if you have multiple CUDA devices.\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/mrnn\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_training = V[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_validating = V[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vazao_CA</th>\n",
       "      <th>Vazao1_CA_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>329</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>67</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>347</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>390</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>333</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>225</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Vazao_CA  Vazao1_CA_1d\n",
       "0          335         335.0\n",
       "1          329         329.0\n",
       "2          278         278.0\n",
       "3          250         250.0\n",
       "4          183         183.0\n",
       "...        ...           ...\n",
       "6995        67          67.0\n",
       "6996       347         347.0\n",
       "6997       390         390.0\n",
       "6998       333         333.0\n",
       "6999       225         225.0\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/hartb/Estudos/vazao/pyopts.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hartb/Estudos/vazao/pyopts.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mrnn\u001b[39m.\u001b[39mfit(train_set\u001b[39m=\u001b[39mdataset_for_training, val_set\u001b[39m=\u001b[39mdataset_for_validating)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/mrnn/model.py:166\u001b[0m, in \u001b[0;36mMRNN.fit\u001b[0;34m(self, train_set, val_set, file_type)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     train_set: Union[\u001b[39mdict\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# Step 1: wrap the input data with classes Dataset and DataLoader\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     training_set \u001b[39m=\u001b[39m DatasetForMRNN(\n\u001b[1;32m    167\u001b[0m         train_set, return_labels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, file_type\u001b[39m=\u001b[39mfile_type\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     training_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    170\u001b[0m         training_set,\n\u001b[1;32m    171\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    172\u001b[0m         shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    173\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     val_loader \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/mrnn/data.py:46\u001b[0m, in \u001b[0;36mDatasetForMRNN.__init__\u001b[0;34m(self, data, return_labels, file_type)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     42\u001b[0m     data: Union[\u001b[39mdict\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m     43\u001b[0m     return_labels: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m     file_type: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mh5py\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[0;32m---> 46\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(data, return_labels, file_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/imputation/brits/data.py:49\u001b[0m, in \u001b[0;36mDatasetForBRITS.__init__\u001b[0;34m(self, data, return_labels, file_type)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     data: Union[\u001b[39mdict\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m     46\u001b[0m     return_labels: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m     file_type: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mh5py\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m ):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(data, return_labels, file_type)\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     52\u001b[0m         \u001b[39m# calculate all delta here.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         forward_missing_mask \u001b[39m=\u001b[39m (\u001b[39m~\u001b[39mtorch\u001b[39m.\u001b[39misnan(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX))\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pypots/data/base.py:76\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, data, return_labels, file_type)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_handle\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m     73\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mThe given dataset file doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contains X. Please double check.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# data from array\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     X \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     77\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m data[\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X'"
     ]
    }
   ],
   "source": [
    "mrnn.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:33:27 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Database)...\n",
      "2023-11-03 19:33:27 [INFO]: Starting preprocessing physionet_2012...\n",
      "2023-11-03 19:33:27 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2023-11-03 19:33:27 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2023-11-03 19:33:27 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2023-11-03 19:33:27 [INFO]: Loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from pypots.data.generating import gene_physionet2012\n",
    "physionet2012_dataset = gene_physionet2012(artificially_missing_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7672"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(physionet2012_dataset['train_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 48, 37)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physionet2012_dataset['val_X_intact'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7672, 48, 37)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physionet2012_dataset['train_X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
